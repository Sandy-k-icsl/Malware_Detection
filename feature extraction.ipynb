{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "from urllib.error import ContentTooShortError\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import Request, urlopen\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support.expected_conditions import presence_of_element_located\n",
    "import time\n",
    "import sys\n",
    "from urllib3 import HTTPConnectionPool\n",
    "import base64\n",
    "import urllib\n",
    "import socket\n",
    "import urllib3\n",
    "from urllib3.exceptions import ProtocolError\n",
    "from urllib3.exceptions import ReadTimeoutError\n",
    "from urllib3.exceptions import DecodeError\n",
    "from requests.exceptions import MissingSchema, InvalidURL, ChunkedEncodingError,ContentDecodingError, ConnectionError, StreamConsumedError\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#options = Options()\n",
    "#options.add_argument(\"--headless\")\n",
    "#driver = webdriver.Chrome(options=options)\n",
    "driver = webdriver.PhantomJS()\n",
    "#driver = webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#options = FirefoxOptions()\n",
    "#options.add_argument(\"--headless\")\n",
    "#driver = webdriver.Firefox(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('top-1m.csv')\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_f = dataset[22:222]\n",
    "dataset_f = dataset[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save to file\n",
    "dataset_f.to_csv(\"apriori.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_f = pd.read_csv('apriori.csv')\n",
    "dataset_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_f.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Line Counts\n",
    "def line_count(url):\n",
    "    if not re.match(r\"^https?\", url):\n",
    "         url = \"http://\" + url\n",
    "    try:\n",
    "        r = requests.get(url, stream = True)\n",
    "        count=0\n",
    "        for i in r.iter_lines():\n",
    "            if i:\n",
    "                count=count+1\n",
    "        return count\n",
    "    except (URLError,HTTPError,ContentTooShortError)  as e:\n",
    "        return -1    \n",
    "    except requests.ConnectionError as e:\n",
    "        return -1\n",
    "    except UnicodeError as e:\n",
    "        return -1  \n",
    "    except ConnectionResetError as e:\n",
    "        return -1\n",
    "    except OSError as e:\n",
    "        return -1\n",
    "    except ProtocolError as e:\n",
    "        return -1\n",
    "    except ReadTimeoutError  as e:\n",
    "        return -1\n",
    "    except RuntimeError as e:\n",
    "        return -1\n",
    "    except ChunkedEncodingError as e:\n",
    "        return -1\n",
    "    except ReadTimeoutError as e:\n",
    "        return -1\n",
    "    except DecodeError as e:\n",
    "        return -1\n",
    "    except ContentDecodingError as e:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Max Length\n",
    "def max_length_line_count(url):\n",
    "    if not re.match(r\"^https?\", url):\n",
    "         url = \"http://\" + url\n",
    "    try:\n",
    "        r = requests.get(url, stream = True)\n",
    "        max_length = 0\n",
    "        max_len_line= ''\n",
    "        for i in r.iter_lines():\n",
    "            if (len(i)>max_length):\n",
    "                max_length=len(i)\n",
    "                max_len_line = i\n",
    "        return(len(max_len_line))\n",
    "    except (URLError,HTTPError,ContentTooShortError)  as e:\n",
    "        return -1    \n",
    "    except requests.ConnectionError as e:\n",
    "        return -1\n",
    "    except UnicodeError as e:\n",
    "        return -1\n",
    "    except ConnectionResetError as e:\n",
    "        return -1\n",
    "    except OSError as e:\n",
    "        return -1\n",
    "    except ProtocolError as e:\n",
    "        return -1\n",
    "    except ReadTimeoutError  as e:\n",
    "        return -1\n",
    "    except RuntimeError as e:\n",
    "        return -1\n",
    "    except ChunkedEncodingError as e:\n",
    "        return -1\n",
    "    except ReadTimeoutError as e:\n",
    "        return -1\n",
    "    except DecodeError as e:\n",
    "        return -1\n",
    "    except ContentDecodingError as e:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requesting to get access to webpage\n",
    "def response_check(url):\n",
    "    if not re.match(r\"^https?\", url):\n",
    "         url = \"http://\" + url\n",
    "    try:\n",
    "        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        return response\n",
    "        #webpage = urlopen(req).read()\n",
    "    except (URLError,HTTPError,ContentTooShortError)  as e:\n",
    "        return False    \n",
    "    except requests.ConnectionError:\n",
    "        return False\n",
    "    except UnicodeError:\n",
    "        return False\n",
    "    except ConnectionResetError as e:\n",
    "        return False\n",
    "    except OSError as e:\n",
    "        return False\n",
    "    except ProtocolError as e:\n",
    "        return False\n",
    "    except ReadTimeoutError  as e:\n",
    "        return False\n",
    "    except RuntimeError as e:\n",
    "        return False\n",
    "    except ChunkedEncodingError as e:\n",
    "        return False\n",
    "    except ReadTimeoutError as e:\n",
    "        return False\n",
    "    except DecodeError as e:\n",
    "        return False\n",
    "    except ContentDecodingError as e:\n",
    "        return False\n",
    "    except AttributeError as e:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Checking for abnormal value for elements\n",
    "\"\"\"Attackers use invisible attributes to hide their elements and set the width\n",
    "and height of elements used to deliver the attack to small values\"\"\"\n",
    "def elements_small_area(response):\n",
    "    if(response!=False):\n",
    "        res = BeautifulSoup(response.text, 'html.parser')\n",
    "        count = 0\n",
    "        types = ['div','iframe','object']\n",
    "        for t in types:\n",
    "            elements = res.find_all(t, height = True, width = True)\n",
    "            for e in elements:\n",
    "                attrs = e.attrs\n",
    "                try:\n",
    "                    h = int(attrs['height'])\n",
    "                    w = int(attrs['width'])\n",
    "                    if h <= 2 or w <= 2:\n",
    "                        count += 1\n",
    "                        continue\n",
    "                    if h * w <= 30:\n",
    "                        count += 1\n",
    "                except:\n",
    "                    continue\n",
    "        return count \n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. WhiteSpace Ratio\n",
    "def whitespace_count(response):\n",
    "    if(response!=False):\n",
    "        char_count = len(response.text)\n",
    "        r = BeautifulSoup(response.text, 'html.parser')\n",
    "        try:\n",
    "            white_space = str(r).count('')\n",
    "            return float(white_space)/float(char_count)\n",
    "        except ZeroDivisionError as e:\n",
    "            return 0  \n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. External JavaScripts\n",
    "def external_javascript_file_count(url):\n",
    "    if not re.match(r\"^https?\", url):\n",
    "        url = \"http://\" + url\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        page = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "        return len(page.findAll(\"script\",src= True))\n",
    "    except TimeoutException as e:\n",
    "        return -1 \n",
    "    except (URLError,HTTPError,ContentTooShortError)  as e:\n",
    "        return -1    \n",
    "    except requests.ConnectionError as e:\n",
    "        return -1\n",
    "    except UnicodeError as e:\n",
    "        return -1  \n",
    "    except ConnectionResetError as e:\n",
    "        return -1\n",
    "    except OSError as e:\n",
    "        return -1\n",
    "    except ProtocolError as e:\n",
    "        return -1\n",
    "    except ReadTimeoutError  as e:\n",
    "        return -1\n",
    "    except RuntimeError as e:\n",
    "        return -1\n",
    "    except ChunkedEncodingError as e:\n",
    "        return -1\n",
    "    except ReadTimeoutError as e:\n",
    "        return -1\n",
    "    except DecodeError as e:\n",
    "        return -1\n",
    "    except ContentDecodingError as e:\n",
    "        return -1      \n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. num JavaScripts\n",
    "def javascript_count(url):\n",
    "    if not re.match(r\"^https?\", url):\n",
    "        url = \"http://\" + url\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        page = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "        return len(page.findAll(\"script\"))\n",
    "    except TimeoutException as e:\n",
    "        return -1 \n",
    "    except (URLError,HTTPError,ContentTooShortError)  as e:\n",
    "        return -1    \n",
    "    except requests.ConnectionError as e:\n",
    "        return -1\n",
    "    except UnicodeError as e:\n",
    "        return -1  \n",
    "    except ConnectionResetError as e:\n",
    "        return -1\n",
    "    except OSError as e:\n",
    "        return -1\n",
    "    except ProtocolError as e:\n",
    "        return -1\n",
    "    except ReadTimeoutError  as e:\n",
    "        return -1\n",
    "    except RuntimeError as e:\n",
    "        return -1\n",
    "    except ChunkedEncodingError as e:\n",
    "        return -1\n",
    "    except ReadTimeoutError as e:\n",
    "        return -1\n",
    "    except DecodeError as e:\n",
    "        return -1\n",
    "    except ContentDecodingError as e:\n",
    "        return -1        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Number of iframes\n",
    "def iframe_count(url):\n",
    "    if not re.match(r\"^https?\", url):\n",
    "        url = \"http://\" + url\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        page = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "        return len(page.findAll(\"iframe\"))\n",
    "    except TimeoutException as e:\n",
    "        return -1\n",
    "    except (URLError,HTTPError,ContentTooShortError)  as e:\n",
    "        return -1    \n",
    "    except requests.ConnectionError as e:\n",
    "        return -1\n",
    "    except UnicodeError as e:\n",
    "        return -1  \n",
    "    except ConnectionResetError as e:\n",
    "        return -1\n",
    "    except OSError as e:\n",
    "        return -1\n",
    "    except ProtocolError as e:\n",
    "        return -1\n",
    "    except ReadTimeoutError  as e:\n",
    "        return -1\n",
    "    except RuntimeError as e:\n",
    "        return -1\n",
    "    except ChunkedEncodingError as e:\n",
    "        return -1\n",
    "    except ReadTimeoutError as e:\n",
    "        return -1\n",
    "    except DecodeError as e:\n",
    "        return -1\n",
    "    except ContentDecodingError as e:\n",
    "        return -1         \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Obfuscation and Suspicious functions\n",
    "def extract_obfus_func(url):\n",
    "    if not re.match(r\"^https?\", url):\n",
    "        url = \"http://\" + url\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        Obfus_functions = ['eval(','fromCharCode(', 'unescape(','escape(','Math.random',\n",
    "                      'ADODB.Stream','CreateObject(','WScript.Shell','FileSystemOject(','FileExists(',\n",
    "                       'charAt(','charCodeAt(','substr(']\n",
    "        count = 0\n",
    "        for t in Obfus_functions:\n",
    "            elements = driver.page_source.count(t)\n",
    "            count += elements\n",
    "        return count      \n",
    "    except TimeoutException as e:\n",
    "        return -1 \n",
    "    except (URLError,HTTPError,ContentTooShortError)  as e:\n",
    "        return -1    \n",
    "    except requests.ConnectionError as e:\n",
    "        return -1\n",
    "    except UnicodeError as e:\n",
    "        return -1  \n",
    "    except ConnectionResetError as e:\n",
    "        return -1\n",
    "    except OSError as e:\n",
    "        return -1\n",
    "    except ProtocolError as e:\n",
    "        return -1\n",
    "    except ReadTimeoutError  as e:\n",
    "        return -1\n",
    "    except RuntimeError as e:\n",
    "        return -1\n",
    "    except ChunkedEncodingError as e:\n",
    "        return -1\n",
    "    except ReadTimeoutError as e:\n",
    "        return -1\n",
    "    except DecodeError as e:\n",
    "        return -1\n",
    "    except ContentDecodingError as e:\n",
    "        return -1        \n",
    "    \n",
    "  \n",
    "   \n",
    "    \n",
    "        \n",
    "       \n",
    "           \n",
    "            \n",
    "            \n",
    "        \n",
    "         \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. frequency of var and function\n",
    "def freq_var_function(url):\n",
    "    if not re.match(r\"^https?\", url):\n",
    "        url = \"http://\" + url\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        keyword_func = ['var','function']\n",
    "        count = 0\n",
    "        for t in keyword_func:\n",
    "            func = driver.page_source.count(t)\n",
    "            count += func\n",
    "        return count      \n",
    "    except TimeoutException as e:\n",
    "        return -1\n",
    "    except (URLError,HTTPError,ContentTooShortError)  as e:\n",
    "        return -1    \n",
    "    except requests.ConnectionError as e:\n",
    "        return -1\n",
    "    except UnicodeError as e:\n",
    "        return -1  \n",
    "    except ConnectionResetError as e:\n",
    "        return -1\n",
    "    except OSError as e:\n",
    "        return -1\n",
    "    except ProtocolError as e:\n",
    "        return -1\n",
    "    except ReadTimeoutError  as e:\n",
    "        return -1\n",
    "    except RuntimeError as e:\n",
    "        return -1\n",
    "    except ChunkedEncodingError as e:\n",
    "        return -1\n",
    "    except ReadTimeoutError as e:\n",
    "        return -1\n",
    "    except DecodeError as e:\n",
    "        return -1\n",
    "    except ContentDecodingError as e:\n",
    "        return -1                  \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. DOM Methods\n",
    "def dom_methods(url):\n",
    "    if not re.match(r\"^https?\", url):\n",
    "        url = \"http://\" + url\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        dom_elements = ['appendChild(','insertBefore(','createElement(','getAttribute(','getElementById(',\n",
    "                   'getElementsByTagName(','parentNode','cloneNode(','setAttribute(','getElementsByClassName(']\n",
    "        count = 0 \n",
    "        for t in dom_elements:\n",
    "            dom =  driver.page_source.count(t)\n",
    "            count += dom\n",
    "        return count\n",
    "    except TimeoutException as e:\n",
    "        return -1 \n",
    "    except (URLError,HTTPError,ContentTooShortError)  as e:\n",
    "        return -1    \n",
    "    except requests.ConnectionError as e:\n",
    "        return -1\n",
    "    except UnicodeError as e:\n",
    "        return -1  \n",
    "    except ConnectionResetError as e:\n",
    "        return -1\n",
    "    except OSError as e:\n",
    "        return -1\n",
    "    except ProtocolError as e:\n",
    "        return -1\n",
    "    except ReadTimeoutError  as e:\n",
    "        return -1\n",
    "    except RuntimeError as e:\n",
    "        return -1\n",
    "    except ChunkedEncodingError as e:\n",
    "        return -1\n",
    "    except ReadTimeoutError as e:\n",
    "        return -1\n",
    "    except DecodeError as e:\n",
    "        return -1\n",
    "    except ContentDecodingError as e:\n",
    "        return -1               \n",
    "\n",
    "\n",
    "    \n",
    "   \n",
    "   \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "            \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an array to store values\n",
    "line_counts = []\n",
    "max_length_line = []\n",
    "small_area= []\n",
    "whitespace_counts = []\n",
    "external_javascript_count = []\n",
    "javascript_counts = []\n",
    "iframe_counts = []\n",
    "Obfus_Suspicious_functions = []\n",
    "var_function = []\n",
    "dom_method = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting features\n",
    "def extract():\n",
    "    counter = 0\n",
    "    for url in dataset_f['URL']:\n",
    "        counter = counter + 1\n",
    "        print(counter)\n",
    "        response = response_check(url)\n",
    "        iframe_counts.append(iframe_count(url))\n",
    "        javascript_counts.append(javascript_count(url))\n",
    "        small_area.append(elements_small_area(response))\n",
    "        line_counts.append(line_count(url))\n",
    "        max_length_line.append(max_length_line_count(url))\n",
    "        whitespace_counts.append(whitespace_count(response))\n",
    "        external_javascript_count.append(external_javascript_file_count(url))\n",
    "        Obfus_Suspicious_functions.append(extract_obfus_func(url))\n",
    "        var_function.append(freq_var_function(url))\n",
    "        dom_method.append(dom_methods(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if extraction was done\n",
    "print(f'iframe              : {len(iframe_counts)}')\n",
    "print(f'small area              : {len(small_area)}')\n",
    "print(f'line_counts             : {len(line_counts)}')\n",
    "print(f'maximum length of line             : {len(max_length_line)}')\n",
    "print(f'whitespace_counts              : {len(whitespace_counts)}')\n",
    "print(f'external JavaScript              : {len(external_javascript_count)}')\n",
    "print(f'Number of JavaScript              : {len(javascript_counts)}')\n",
    "print(f'The number of Obfuscation functions in this url: {len(Obfus_Suspicious_functions)}')\n",
    "print(f'The number of var and function() in this url: {len(var_function)}')\n",
    "print(f'The number of dom_methods() in this url: {len(dom_method)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe to add extracted features columns previous dataset \n",
    "features_df = pd.DataFrame(dataset_f)\n",
    "features_df['iframe_count'] = iframe_counts\n",
    "features_df['small_area'] = small_area\n",
    "features_df['line_counts'] = line_counts\n",
    "features_df['max_length_line'] = max_length_line\n",
    "features_df['space_%'] = whitespace_counts\n",
    "features_df['js_count'] = javascript_counts \n",
    "features_df['ext_js_count'] = external_javascript_count\n",
    "features_df['obfus_suspicious_func_count'] = Obfus_Suspicious_functions \n",
    "features_df['var_function'] = var_function\n",
    "features_df['dom_counts'] = dom_method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save to file\n",
    "features_df.to_csv(\"apriori_features.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
